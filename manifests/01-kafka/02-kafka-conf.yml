apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-config
  namespace: kafka
data:
  kafka_server_jaas.conf: |
    KafkaServer {
      org.apache.kafka.common.security.plain.PlainLoginModule required
      username="admin"
      password="test1234"
      user_admin="test1234"
      user_test="test";
    };

  admin.properties: |
    security.protocol=SASL_PLAINTEXT
    sasl.mechanism=PLAIN
    sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="admin" password="test1234";

  server.properties: |
    listeners=INTERNAL://:9093,EXTERNAL://:9092,CLUSTER://:9094,CONTROLLER://:9095
    listener.security.protocol.map=INTERNAL:SASL_PLAINTEXT,EXTERNAL:SASL_PLAINTEXT,CLUSTER:SASL_PLAINTEXT,CONTROLLER:SASL_PLAINTEXT
    inter.broker.listener.name=INTERNAL
    sasl.enabled.mechanisms=PLAIN
    sasl.mechanism.inter.broker.protocol=PLAIN
    sasl.mechanism.controller.protocol=PLAIN

    ### ACLs ###
    # authorizer.class.name=org.apache.kafka.metadata.authorizer.StandardAuthorizer
    super.users=User:admin

    ### Raft ###
    node.id=0
    process.roles=broker,controller
    controller.listener.names=CONTROLLER
    controller.quorum.voters=0@kafka-0.kafka.kafka.svc:9095,1@kafka-1.kafka.kafka.svc:9095,2@kafka-2.kafka.kafka.svc:9095

    log.dir=/var/lib/kafka
    auto.create.topics.enable=false
    auto.leader.rebalance.enable=true
    background.threads=10
    compression.type=producer
    delete.topic.enable=true
    leader.imbalance.check.interval.seconds=300
    leader.imbalance.per.broker.percentage=10
    log.segment.bytes=1073741824
    log.segment.delete.delay.ms=60000
    message.max.bytes=1000012
    min.insync.replicas=1
    num.io.threads=12
    num.network.threads=4
    num.recovery.threads.per.data.dir=1
    num.replica.fetchers=4
    offset.metadata.max.bytes=4096
    offsets.commit.required.acks=-1
    offsets.commit.timeout.ms=5000
    offsets.load.buffer.size=5242880
    offsets.retention.check.interval.ms=600000
    offsets.retention.minutes=1440
    offsets.topic.compression.codec=0
    offsets.topic.num.partitions=50
    offsets.topic.replication.factor=1
    offsets.topic.segment.bytes=104857600
    queued.max.requests=500
    quota.consumer.default=9223372036854775807
    quota.producer.default=9223372036854775807
    replica.fetch.min.bytes=1
    replica.fetch.wait.max.ms=500
    replica.high.watermark.checkpoint.interval.ms=5000
    replica.lag.time.max.ms=10000
    #replica.socket.receive.buffer.bytes=65536
    replica.socket.receive.buffer.bytes=102400
    replica.socket.timeout.ms=30000
    request.timeout.ms=30000
    socket.receive.buffer.bytes=102400
    socket.request.max.bytes=104857600
    socket.send.buffer.bytes=102400
    unclean.leader.election.enable=true
    # zookeeper.session.timeout.ms=6000
    broker.id.generation.enable=true
    connections.max.idle.ms=600000
    controlled.shutdown.enable=true
    controlled.shutdown.max.retries=3
    controlled.shutdown.retry.backoff.ms=5000
    controller.socket.timeout.ms=30000
    default.replication.factor=3
    fetch.purgatory.purge.interval.requests=1000
    group.max.session.timeout.ms=300000
    group.min.session.timeout.ms=6000
    log.cleaner.backoff.ms=15000
    log.cleaner.dedupe.buffer.size=134217728
    log.cleaner.delete.retention.ms=86400000
    log.cleaner.enable=true
    log.cleaner.io.buffer.load.factor=0.9
    log.cleaner.io.buffer.size=524288
    log.cleaner.io.max.bytes.per.second=1.7976931348623157E308
    log.cleaner.min.cleanable.ratio=0.5
    log.cleaner.min.compaction.lag.ms=0
    log.cleaner.threads=1
    log.cleanup.policy=delete
    log.index.interval.bytes=4096
    log.index.size.max.bytes=10485760
    log.message.timestamp.difference.max.ms=9223372036854775807
    log.message.timestamp.type=CreateTime
    log.preallocate=false
    log.retention.check.interval.ms=300000
    max.connections.per.ip=2147483647
    num.partitions=3
    producer.purgatory.purge.interval.requests=1000
    replica.fetch.backoff.ms=1000
    replica.fetch.max.bytes=1048576
    replica.fetch.response.max.bytes=10485760
    reserved.broker.max.id=1000
